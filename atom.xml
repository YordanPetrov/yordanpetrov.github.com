<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Yordan Petrov @ blogland]]></title>
  <link href="http://YordanPetrov.github.com/atom.xml" rel="self"/>
  <link href="http://YordanPetrov.github.com/"/>
  <updated>2013-03-18T12:39:52+00:00</updated>
  <id>http://YordanPetrov.github.com/</id>
  <author>
    <name><![CDATA[Yordan Petrov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What poor requirements are and how could they impact a project?]]></title>
    <link href="http://YordanPetrov.github.com/blog/2013/03/18/what-poor-requirements-are-and-how-could-they-impact-a-project/"/>
    <updated>2013-03-18T12:37:00+00:00</updated>
    <id>http://YordanPetrov.github.com/blog/2013/03/18/what-poor-requirements-are-and-how-could-they-impact-a-project</id>
    <content type="html"><![CDATA[<p>It is a well-known fact that requirements are one of the most important building blocks of every project. Logically, when they are <em>broken</em>, the overall application will be affected as well. This fact is often backed by surveys investigating the main reasons about project failures. In this post I will explore the notion of &#8220;poor requirements&#8221; by describing what they are and how they could influence the final goal - completing a project successfuly.</p>

<h2>Poor requirements</h2>

<p>Before exploring the concept of a <strong>poor</strong> requirement, we need to define what is the purpose of a requirement. I think this could be described in the following way - a requirement is a mean of narrowing down (or better - constraining) the design choices for a given project. From the exercise we did during <em>Lecture 2</em>[1] (estimating how long building a Java to HTML translator will take), we could see that not specifying the full set of requirements led to a big difference in the different attemps of estimation the least. And estimation is only part of the whole problem. With the simple specification of &#8220;Java to HTML translator&#8221; many questions about the details are left unanswered, e.g. what technologies should be used, how should invalid inputs be handled, etc. By putting more strict requirements like &#8220;The system shall display an error message on invalid inputs&#8221;, etc., we narrow down the design choices one could make during execution and hence it is more probable for us to end up with the product that is actually desired.</p>

<p><strong>Poor requirements</strong> could be split into three different categories:</p>

<ol>
<li><strong>Bad</strong> -
Karl Wiegers[2] defines several characteristics of high quality software requirement statements and specifications as a whole. While single requirements need to be <em>correct</em>, <em>feasible</em>, <em>unambiguous</em>, <em>measurable</em> etc., the set of all requirements (specification) has to be <em>complete</em>, consistent, <em>traceable</em>, etc. All of those qualities prevent <strong>scope creep</strong>, which is one of the leading causes of requirements related failures, from occuring. Based on this, we define <strong>bad</strong> requirements are as ones lacking any of the aforementioned properties. While it is true that there can never be perfect requirements, everyone will agree that better products are achieved using better specifications, i.e. ones having as many of Karl Wiegers&#8217;s features as possible. For example in the above case from <em>Lecture 2</em> if we have a requirement stating &#8220;The system shall be easy to use&#8221;, then this could be considered as <strong>bad</strong> requirement as this cannot be directly measured.
<strong>Useless</strong> -
Useless requirements are those which do not bring any more information which will influence the design decisions. For example, if we have a requirement &#8220;the translator should work correctly&#8221;, then this will be a useless one. The reason for that is this could be inferenced by our definition - noone would want a translator that does not work. This type of requirements seem harmless at first, but fact that they need to be analysed, acknowledged and planned for wastes time, resources and energy.</li>
<li><strong>Absent</strong> -
<strong>Absent</strong> requirements are those that are needed but are nonexistent in the specification. In the case when designers are in situation presenting them with the problem of having nonexistent requirements, if they spot this fact, more often than not they will need to make the design choices based on their experience, preferences and time available.</li>
</ol>


<h2>Impact</h2>

<p>Why are poor requirements bad for our software project? To put it simply - the less the quality of the requirements is, the higher the chance that our project will fail (or have serious flaws) will be. Since a project usually consists of roughly two main teams - the technology one and the business one, having poor requirements will affect both of them. Below we explore how each one of them is individually impacted.</p>

<ol>
<li><strong>Technology team</strong> - There are many problems that the technology team could face, but the main one is probably <strong>late delivery</strong>. Due to the fact that the specification is flawed, every other aspect of the project that is based on it (design, testing, etc.) will deteriorate. When the flaws are uncovered, many parts of a product will need to be revisited and this could most certainly contribute to extending the delivery date. Design is another aspect that weakens as multiple changes are made because of erroneous requirements. When the design is created, it is based on a plethora of factors, patterns and experience and this becomes corrupted with every itteraction caused by an uncovered poor requirement. Lastly -  the quality of the final product is more likely to be bad. The reason behind this is the wasted time which is often spent on testing requirements which are later changed. Testing should be a main priority in a project and as much time as possible should be dedicated to it. However, if the requirements are poor, then this certainbly is not going to be case.</li>
<li><strong>Business team</strong> - Even a non-expert will notice that all of the aforementioned troubles can stongly impact many parts of the business side of a product. For example, poor quality directly affects the end customers. Then, if customers are affected, so will the profitability and the market share of the product be. Althought none of these consequences can be predicted precisely, what could be predicted is that their effect will not be desired. In terms of the planning side of project, the outcome of having poor requirements will be a prolonged execution process. This, in turn will result in needing a higher final budget (it will be more costly) than predicted.</li>
</ol>


<h2>Conclusion</h2>

<p>Despite the fact that everything I have mentioned so far is true, one should always keep in mind that there is no formulaic way of defining perfect requirements which will work in all situations. The best way to go about writing good requirements is to learn from experience, i.e. the requirements of the problems one has encountered in the past. To sum up, I will borrow a quote from [2]:</p>

<blockquote><p>&#8221;..remember that without high quality requirements, software is like a box of chocolates: you never know what you’re going to get.&#8221;</p></blockquote>

<br>


<h2>References:</h2>

<p>[1] http://www.inf.ed.ac.uk/teaching/courses/sapm/2012-2013/project-management.pdf
[2] Writing quality requirements, http://www.processimpact.com/articles/qualreqs.html</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why scripting languages should be encouraged for university courseworks?]]></title>
    <link href="http://YordanPetrov.github.com/blog/2013/03/18/why-scripting-languages-should-be-encouraged-for-university-courseworks/"/>
    <updated>2013-03-18T12:26:00+00:00</updated>
    <id>http://YordanPetrov.github.com/blog/2013/03/18/why-scripting-languages-should-be-encouraged-for-university-courseworks</id>
    <content type="html"><![CDATA[<p>Why scripting languages should be encouraged for university courseworks?</p>

<p>During their time at university students often have to do courseworks. More often than not those courseworks involve a coding element. Whether it will be designing a model, simulating a technical concept or implementing an algorithm, a choice about the implementation and the programming language to be used needs to be made. Sometimes, this choice is made by the lecturer, but there are times when this is not the case and when it comes down to the students to decide. What I think is that not only should students choose scripting programming languages for most of their tasks, but also that lecturers should encourage their usage, too. My opinion expands on the topic of transition from system to scripting programming explored in John K. Ousterhout&#8217;s article – <strong>Scripting: Higher-Level Programming for the 21st Century</strong>[1].</p>

<p>There has been a heated discussion on which type of language is the better one. In my opinion the answer to this question is that it depends on the case. Hence, I am exploring the case of students and their university work. First, let me briefly explain what are the main differences between the system programming languages and the scripting programming languages[2]. I will focus on three of them, which I believe are the most important ones:</p>

<ol>
<li><p><strong>High-level vs. Low-level</strong>: Scripting languages are higher level compared to system languages in the sense that a single “scripting” statement does more than a single “system” statement. This means that if, for example, each line of code written in a system language is translated into 5 lines of machine code, the respective amount for scripting languages will be in the magnitude of hundreds or thousands. The consequence of this is that the amount of code one needs to write in order to accomplish a task would be much less if they used a scripting language. Moreover, using a high-level language means that the programmer need not worry about detailed control over the program flow and/or memory allocation, since this has already been handled for them.</p></li>
<li><p><strong>Compiled vs. Interpreted</strong>: System languages are compiled, which means that the code that is written is reduced to a set of machine-specific instructions upfront. On the other hand, scripting languages are usually interpreted, i.e. code is saved in the same format that it is written and it is at runtime that is it translated into machine instructions. In theory, compiled programs run faster as there is no translation happening at runtime and also, it is easier for the compiler to do upfront optimisations. However, the interpreted programs provide more flexibility with that they can modify themselves at runtime by adding or editing functions. The disadvantage imposed by this is that they are not as efficient and fast as the compiled ones. Most of the cases this is easily overcome by the fact that nowadays computers are hundreds of times faster than what they used to be 10 or 20 years ago. The disadvantage which is a result of programs having to be compiled beforehand is the fact that development times are not as rapid as they could be, because of compilation times.</p></li>
<li><p><strong>Static Typing vs. Dynamic Typing</strong>: System languages are statically typed, which means that the programmer needs to specify how each piece of information is going to be used (e.g. variable needs to be of particular types and hence must be used according to that definition), and the language prevents improper usage of that information. In comparison to that, scripting programming languages are dynamically typed, i.e. the type of an object is decided only at runtime and there is no upfront restriction on how information should be used. While static typing has its advantages – it makes large projects more manageable, helps in early detection of errors and contributes to compiler optimisations, dynamic typing has its advantages, too. It gives more flexibility and freedom when designing a program and it is usually more concise as a lot of boilerplate code could be removed. This leads to shorter code which is not only quicker to write, but also quicker to read and maintain/change.
How are all those things relevant to the topic and why would students benefit more from using, say, an interpreted, dynamically typed language? In order to answer this, we need to analyse what are the typical problems that students face. Usually, a coursework consists of an isolated problem which is designed such that it could be solved in a relatively short period of time. In this short period, a student is supposed to both do the background reading which will allow them to do the coursework and do the actual implementation. This means that they do not have a great deal of time they could spend on simply writing code. Everyone knows that implementing code is an iterative process, so being able to prototype things quickly is essential. By taking the focus off the actual coding, this allows for more time to be spent on the actual “solving” of the problem. And there is the first important argument – having the ability to quickly write short code that just works will most likely be beneficial for not only getting a coursework done, but also for learning more (since more time is spent on thinking and hence the design process).</p></li>
</ol>


<p>So, following this train of thought, what would be the better choice of programming language – a scripting one or a system one? I believe it is the former. Why? Because as already mentioned, scripting languages are <strong>higher-level</strong> languages. The result of that is that the programmer will be able to express what they want in fewer lines or code and without worrying about low-level details. As a student, I am more interested in getting something to work in the shortest period of time possible, than spending great deal of time sorting out pointers or memory allocations. Moreover, scripting languages are <strong>interpreted</strong>, i.e. compile times are eliminated and hence testing could be done straight away. Some might argue that a language being interpreted leads to a worse performance. While this is true for applications where the execution speed is critical, in the general case this is not a problem, because of the speed of the computers nowadays. And in the general case, the focus of the courseworks is on implementing a given concept or a technique right, rather than implementing it so it runs in the fastest possible way. Moreover, the other advantage that I mentioned earlier (programs can modify themselves at runtime) could be very useful for certain types of problems. Lastly, <strong>dynamic typing</strong>. Many people will argue that this is a bad idea when it comes to large projects which need to be maintained in the future and I will probably agree with them. But as we all know, students assignments are usually not big in size and more often than not their implementations do not exceed a few hundred lines of code. What&#8217;s more, dynamically typed languages give freedom, so the programmer can just focus on getting things done and not worry about types, declarations, etc.</p>

<p>To make it clear – I do not state that using scripting languages in all cases is the best thing to do. Of course, there will be times where system languages will be the preferable choice (due to issues like performance, finer memory control, etc). My argument is that in the general case, students will gain and learn more if they choose to use a scripting language.</p>

<p>References:</p>

<p>[1] Scripting: Higher-Level Programming for the 21st Century, John K Outerhout, Sun Microsystems Laboratories, http://www.stanford.edu/~ouster/cgi-bin/papers/scripting.pdf</p>

<p>[2] By “system languages” I will mean languages like C, Java, C++ and by “scripting languages” I will refer to languages like Python, Ruby, Perl.</p>
]]></content>
  </entry>
  
</feed>
